{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.4362964   0.         ...  0.          1.\n",
      "   0.        ]\n",
      " [ 1.          0.18877218  0.         ...  0.          1.\n",
      "   0.        ]\n",
      " [ 1.         -0.62211856  0.         ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 1.          0.56302944  0.         ...  0.          1.\n",
      "   0.        ]\n",
      " [ 1.          0.18877218  0.         ...  0.          1.\n",
      "   0.        ]\n",
      " [ 1.          0.12639597  0.         ...  0.          1.\n",
      "   0.        ]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "1414\n",
      "328135\n",
      "1\n",
      "1414\n",
      "当前迭代次数：0, 损失：0.02751289796667825\n",
      "当前迭代次数：100, 损失：0.02394028829116565\n",
      "当前迭代次数：200, 损失：0.023661144363907215\n",
      "当前迭代次数：300, 损失：0.02352038267771307\n",
      "当前迭代次数：400, 损失：0.023431769958925482\n",
      "当前迭代次数：500, 损失：0.023371008737592274\n",
      "当前迭代次数：600, 损失：0.02332767969887362\n",
      "当前迭代次数：700, 损失：0.023295892396115847\n",
      "当前迭代次数：800, 损失：0.023271929554719396\n",
      "当前迭代次数：900, 损失：0.023253354812806683\n",
      "[[ 0.00609276]\n",
      " [ 0.01591066]\n",
      " [-0.20514364]\n",
      " ...\n",
      " [-0.01897061]\n",
      " [ 0.00117247]\n",
      " [ 0.02389091]]\n",
      "最终损失: 0.02323868012973748\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from logistic_regression import *\n",
    "from basic_functions import *\n",
    "\n",
    "# load data\n",
    "x_train_pre = np.loadtxt(\"x_train_processed_0_missing_1029.csv\", delimiter=\",\", skiprows=1)\n",
    "y_train = np.loadtxt(\"y_train.csv\", delimiter=\",\", skiprows=1)\n",
    "\n",
    "#提取第二列到最后一列\n",
    "y_train_pre = y_train[:, 1:]  # 这将返回所有行和从第二列开始的所有列\n",
    "x_test_pre = np.loadtxt(\"x_test_processed_0_missing_1029.csv\", delimiter=\",\", skiprows=1)\n",
    "\n",
    "# change the label \n",
    "y_train_pre[y_train_pre == -1] = 0\n",
    "\n",
    "# 添加偏置项\n",
    "tx = np.hstack((np.ones((x_train_pre.shape[0], 1)), x_train_pre))\n",
    "tx_test = np.hstack((np.ones((x_test_pre.shape[0], 1)), x_test_pre))\n",
    "\n",
    "# 加载sample-submission中的Id列\n",
    "sample_submission = np.loadtxt('sample-submission.csv', delimiter=',', skiprows=1, usecols=0, dtype=int)\n",
    "\n",
    "# 初始化参数\n",
    "initial_w = np.zeros((tx.shape[1], 1))\n",
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "batch_size = 64  \n",
    "\n",
    "print(tx)\n",
    "print(initial_w)\n",
    "print(tx.shape[1])\n",
    "print(tx.shape[0])\n",
    "print(initial_w.shape[1])\n",
    "print(initial_w.shape[0])\n",
    "\n",
    "def mini_batch_logistic_regression(y, tx, initial_w, max_iters, gamma, batch_size):\n",
    "    w = initial_w\n",
    "    for i in range(max_iters):\n",
    "        for batch_start in range(0, len(y), batch_size):\n",
    "            batch_end = batch_start + batch_size\n",
    "            y_batch = y[batch_start:batch_end]\n",
    "            tx_batch = tx[batch_start:batch_end]\n",
    "            \n",
    "            # 计算损失和梯度\n",
    "            loss = calculate_loss(y_batch, tx_batch, w)\n",
    "            gradient = calculate_gradient(y_batch, tx_batch, w)\n",
    "            \n",
    "            # 更新权重\n",
    "            w = w - gamma * gradient\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"当前迭代次数：{i}, 损失：{loss}\")\n",
    "    return w, loss\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "w,loss= mini_batch_logistic_regression(y_train_pre, tx, initial_w, max_iters, gamma, batch_size)\n",
    "\n",
    "print(w)\n",
    "\n",
    "# 输出最终的损失\n",
    "print(f\"最终损失: {loss}\")\n",
    "\n",
    "# 使用训练好的模型在测试集上进行预测\n",
    "y_pred_test = predict(tx_test, w)\n",
    "\n",
    "y_pred_test = np.where(y_pred_test == 0, -1, y_pred_test)\n",
    "\n",
    "#y_pred_test = np.where(y_pred_test == 0, -1, y_pred_test)\n",
    "\n",
    "# save as .csv\n",
    "header = \"Id,Prediction\"\n",
    "results = np.hstack((sample_submission.reshape(-1, 1), y_pred_test.reshape(-1, 1)))\n",
    "\n",
    "np.savetxt('C:/Users/y/Documents/ml_exercise/ML_project_1/result_logistic_regression.csv', \n",
    "           results, delimiter=',', header=header, comments='', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [nan]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [nan]\n",
      " [nan]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "y_pred_test 中有 46116 个 NaN\n"
     ]
    }
   ],
   "source": [
    "# 使用训练好的模型在测试集上进行预测\n",
    "y_pred_test = predict(tx_test, w)\n",
    "\n",
    "# 查找 y_pred_test 中 NaN 的个数\n",
    "num_nans = np.sum(np.isnan(y_pred_test))\n",
    "print(y_pred_test[:10])\n",
    "print(f\"y_pred_test 中有 {num_nans} 个 NaN\")\n",
    "\n",
    "# 将 y_pred_test 中的 NaN 替换为 -1\n",
    "y_pred_test = np.nan_to_num(y_pred_test, nan=-1)\n",
    "# save as .csv\n",
    "header = \"Id,Prediction\"\n",
    "results = np.hstack((sample_submission.reshape(-1, 1), y_pred_test.reshape(-1, 1)))\n",
    "\n",
    "np.savetxt('C:/Users/y/Documents/ml_exercise/ML_project_1/result_logistic_regression.csv', \n",
    "           results, delimiter=',', header=header, comments='', fmt='%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a test conducted on 10% of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 1414)\n",
      "(32813, 1414)\n",
      "(32813, 1)\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 10% of the data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "num_samples = tx.shape[0]\n",
    "sample_size = int(num_samples * 0.1)\n",
    "indices = np.random.choice(num_samples, sample_size, replace=False)\n",
    "\n",
    "# Extract the sampled training data and labels\n",
    "x_train_sample = tx[indices]\n",
    "y_train_sample = y_train_pre[indices]\n",
    "\n",
    "print(tx.shape)\n",
    "print(x_train_sample.shape)\n",
    "print(y_train_sample.shape)\n",
    "print(y_train_sample[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24736699972994872 0.9150641514034071\n"
     ]
    }
   ],
   "source": [
    "# The prediction results of logistic regression\n",
    "y_pred_sample = predict(x_train_sample, w)\n",
    "f1_score_logiregression=calculate_f1_score(y_pred_sample,y_train_sample)\n",
    "accuracy_logiregression=calculate_accuracy(y_pred_sample,y_train_sample)\n",
    "print(f1_score_logiregression,accuracy_logiregression)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
